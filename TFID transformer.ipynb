{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _____TF-IDF libraries_____\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# _____helper Libraries_____\n",
    "import pickle  # would be used for saving temp files\n",
    "import csv     # used for accessing the dataset\n",
    "import timeit  # to measure time of training\n",
    "import random  # used to get a random number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-24-4a314bc15835>, line 58)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-4a314bc15835>\"\u001b[0;36m, line \u001b[0;32m58\u001b[0m\n\u001b[0;31m    # -----------------------------------------#\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def talk_to_lina_primary(test_set_sentence):\n",
    "   \n",
    "    csv_file_path = \"./bot_reply.csv\"\n",
    "    tfidf_vectorizer_pikle_path = \"./tfidf_vectorizer.pickle\"\n",
    "    tfidf_matrix_train_pikle_path =\"./tfidf_matrix_train.pickle\"\n",
    "\n",
    "    i = 0\n",
    "    sentences = []\n",
    "\n",
    "    # enter your test sentence\n",
    "    test_set = (test_set_sentence, \"\")\n",
    "\n",
    "    # for indexes\n",
    "    sentences.append(\" No you.\")\n",
    "    sentences.append(\" No you.\")\n",
    "\n",
    "    try:\n",
    "        # ---------------to train------------------#\n",
    "        # variable to see how much time it took to train \n",
    "        start = timeit.default_timer()\n",
    "\n",
    "        # to load rows of csv into sentences array\n",
    "        with open(csv_file_path, \"r\") as sentences_file:\n",
    "            reader = csv.reader(sentences_file, delimiter=',')\n",
    "            for row in reader:\n",
    "                sentences.append(row[0])\n",
    "                i += 1\n",
    "    \n",
    "        # now we would start on with trainig\n",
    "        # begin with identing a TfidfVectorizer obj\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "        # this line does both\n",
    "        # 1- identify dimension of the space\n",
    "        # 2- learn tf-idf of the dataset\n",
    "        tfidf_matrix_train = tfidf_vectorizer.fit_transform(sentences) \n",
    "\n",
    "\n",
    "        # now the training is fininshed\n",
    "      \n",
    "        # now simply record time that it finished training\n",
    "        stop = timeit.default_timer()\n",
    "        print (\"training time took was : \")\n",
    "        print (stop - start)\n",
    "\n",
    "        # then we would save these 2 objs (dimension space and tf-idf to temp files)\n",
    "        # we use pickle lib\n",
    "\n",
    "        # first save dimension space\n",
    "        f = open(tfidf_vectorizer_pikle_path, 'wb')\n",
    "        pickle.dump(tfidf_vectorizer, f)\n",
    "        f.close()\n",
    "\n",
    "        # then save tf-idf of dataset\n",
    "        f = open(tfidf_matrix_train_pikle_path, 'wb')\n",
    "        pickle.dump(tfidf_matrix_train, f)\n",
    "        f.close()\n",
    "        # -----------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def talk_to_lina_primary(test_set_sentence):\n",
    "   \n",
    "    csv_file_path = \"bot_reply.csv\"\n",
    "    tfidf_vectorizer_pikle_path = \"/tfidf_vectorizer.pickle\"\n",
    "    tfidf_matrix_train_pikle_path =\"/tfidf_matrix_train.pickle\"\n",
    "\n",
    "    i = 0\n",
    "    sentences = []\n",
    "\n",
    "    # enter your test sentence\n",
    "    test_set = (test_set_sentence, \"what is there to eat in Beijing\")\n",
    "\n",
    "    # 3ashan yzabt el indexes\n",
    "    sentences.append(\" No you.\")\n",
    "    sentences.append(\" No you.\")\n",
    "\n",
    "    try:\n",
    "        ##--------------to use------------------#\n",
    "        f = open(tfidf_vectorizer_pikle_path, 'rb')\n",
    "        tfidf_vectorizer = pickle.load(f)\n",
    "        f.close()\n",
    "\n",
    "        f = open(tfidf_matrix_train_pikle_path, 'rb')\n",
    "        tfidf_matrix_train = pickle.load(f)\n",
    "        f.close()\n",
    "        # ----------------------------------------#\n",
    "    except:\n",
    "        # ---------------to train------------------#\n",
    "        start = timeit.default_timer()\n",
    "\n",
    "        # enter jabberwakky sentence\n",
    "        with open(csv_file_path, \"r\") as sentences_file:\n",
    "            reader = csv.reader(sentences_file, delimiter=',')\n",
    "            # reader.next()\n",
    "            # reader.next()\n",
    "            for row in reader:\n",
    "                # if i==stop_at_sentence:\n",
    "                #    break\n",
    "                sentences.append(row[0])\n",
    "                i += 1\n",
    "\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix_train = tfidf_vectorizer.fit_transform(sentences)  # finds the tfidf score with normalization\n",
    "        # tfidf_matrix_test =tfidf_vectorizer.transform(test_set)\n",
    "        stop = timeit.default_timer()\n",
    "        print (\"training time took was : \")\n",
    "        print (stop - start)\n",
    "\n",
    "        f = open(tfidf_vectorizer_pikle_path, 'wb')\n",
    "        pickle.dump(tfidf_vectorizer, f)\n",
    "        f.close()\n",
    "\n",
    "        f = open(tfidf_matrix_train_pikle_path, 'wb')\n",
    "        pickle.dump(tfidf_matrix_train, f)\n",
    "        f.close()\n",
    "        # -----------------------------------------#\n",
    "\n",
    "    # use the learnt dimension space\n",
    "    # to run TF-IDF on the query\n",
    "    tfidf_matrix_test = tfidf_vectorizer.transform(test_set)\n",
    "\n",
    "    # then run cosine similarity between the 2 tf-idfs\n",
    "    cosine = cosine_similarity(tfidf_matrix_test, tfidf_matrix_train)\n",
    "    cosine = np.delete(cosine, 0)\n",
    "    \n",
    "    # then get the max score\n",
    "    max = cosine.max()\n",
    "    response_index = 0\n",
    "\n",
    "    # if score is more than 0.7\n",
    "    if (max > 0.7): \n",
    "        # we can afford to get multiple high score documents to choose from\n",
    "        new_max = max - 0.01\n",
    "        \n",
    "        # load them to a list\n",
    "        list = np.where(cosine > new_max)\n",
    "        \n",
    "        # choose a random one to return to the user \n",
    "        # this happens to make Lina answers diffrently to same sentence\n",
    "        response_index = random.choice(list[0])\n",
    "\n",
    "    else:\n",
    "        # else we would simply return the highest score\n",
    "        response_index = np.where(cosine == max)[0][0] + 2 \n",
    "       \n",
    "\n",
    "    j = 0\n",
    "\n",
    "    # loop to return the next cell on the row , ( the response cell )\n",
    "    with open(csv_file_path, \"r\") as sentences_file:\n",
    "        reader = csv.reader(sentences_file, delimiter=',')\n",
    "        for row in reader:\n",
    "            j += 1  # we begin with 1 not 0 &    j is initialized by 0\n",
    "            if j == response_index:\n",
    "                return row[1], response_index,\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd2 in position 4682: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7ac5b95a0fa4>\u001b[0m in \u001b[0;36mtalk_to_lina_primary\u001b[0;34m(test_set_sentence)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m##--------------to use------------------#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_vectorizer_pikle_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mtfidf_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tfidf_vectorizer.pickle'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a3c1d6b394c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"talk to Lina : \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresponse_primary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_id_primary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtalk_to_lina_primary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresponse_primary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-7ac5b95a0fa4>\u001b[0m in \u001b[0;36mtalk_to_lina_primary\u001b[0;34m(test_set_sentence)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# reader.next()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# reader.next()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0;31m# if i==stop_at_sentence:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;31m#    break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd2 in position 4682: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "while 1:\n",
    "    sentence = \"talk to Lina : \"\n",
    "\n",
    "    response_primary, line_id_primary = talk_to_lina_primary(sentence)\n",
    "    print (response_primary)\n",
    "    print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
